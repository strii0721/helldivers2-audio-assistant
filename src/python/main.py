from devtoolkit.Log4P import Log4P
from nn.network.CmdNetworkV2 import CmdNetwork
from utils.DatasetUtils import DatasetUtils
from nn.dataset.Preprocessing import Preprocessing
from utils.KeyboardSimulator import KeyboardSimulator

import sounddevice as sd
import torch
import torch.nn.functional as F
import time

if __name__ == "__main__":
    
    DATASET_BASE = "src/resources/dat"
    MODEL_PATH = "src/resources/model.pth"
    
    SAMPLE_RATE = 48000
    INTERVAL = 0.8
    
    THRESHOLD = 0.6
    CMD_TIMEOUT = 3
    
    CMD_DICT = {
        1: ["ç©ºçˆ†", "â†“â†‘â†‘â†â†’"],
        2: ["ç«ç®­ç‚®å¡”", "â†“â†‘â†’â†’â†"],
        3: ["æœºæªç‚®å¡”", "â†“â†‘â†’â†’â†‘"],
        4: ["åŠ å†œç‚®å¡”", "â†“â†‘â†’â†‘â†â†‘"],
        5: ["æ— ååº§", "â†“â†â†’â†’â†"],
        6: ["ç”µç£è¿«å‡»ç‚®", "â†“â†‘â†’â†â†’"],
        7: ["SOS", "â†‘â†“â†’â†‘"],
        8: ["å¢æ´", "â†‘â†“â†’â†â†‘"],
        9: ["è¡¥ç»™", "â†“â†“â†‘â†’"],
        10: ["åœ°ç‹±ç«", "â†“â†‘â†â†“â†‘â†’â†“â†‘"],
        11: ["è½¨é“æ¿€å…‰", "â†’â†“â†‘â†’â†“"],
        12: ["è½¨é“æ±½æ²¹å¼¹", "â†’â†’â†“â†â†’â†‘"],
        13: ["500åƒå…‹", "â†‘â†’â†“â†“â†“"],
    }
    
    logger = Log4P(enable_level = True,
                   enable_timestamp = True,
                   enable_source = True,
                   enable_log_file = False,
                   source = "main",)
    
    keyboardSimulator = KeyboardSimulator()
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    _, category_number = DatasetUtils.get_dataframe_distributed(DATASET_BASE)
    model = CmdNetwork(category_number = category_number).to(device)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model.eval()
    logger.info("ğŸ™ï¸  å¼€å§‹ç›‘å¬éº¦å…‹é£...")
    command_start = False
    while True:
        audio = sd.rec(int(SAMPLE_RATE * INTERVAL), samplerate = SAMPLE_RATE, channels = 2)
        sd.wait()
        audio = torch.tensor(audio.T, dtype=torch.float32) # [1, num_samples]

        audio = Preprocessing.isometricalization(audio = audio,
                                                 sample_rate = SAMPLE_RATE,
                                                 length = INTERVAL)
        audio = Preprocessing.mono(audio = audio)
        audio = Preprocessing.mel_spectrogram(audio = audio,
                                              sample_rate = SAMPLE_RATE)
        audio = audio.unsqueeze(0)   
        with torch.no_grad():
            audio = audio.to(device) 
            output = model(audio)
            probs = F.softmax(output, dim=1)           # æ¦‚ç‡åˆ†å¸ƒ
            max_prob, pred_index = torch.max(probs, 1) # è·å–æœ€å¤§æ¦‚ç‡åŠå…¶ç´¢å¼•
            max_prob = max_prob.item()
            pred_index = pred_index.item()
            if max_prob >= THRESHOLD and pred_index != 0:
                if pred_index == 14:
                     keyboardSimulator.start()
                     command_start = True
                     logger.info(f"âœ…  æŒ‡ä»¤ï¼š")
                     ticker = time.time()
                else:
                    if command_start:
                        command_name = CMD_DICT[pred_index][0]
                        command_sequence = CMD_DICT[pred_index][1]
                        keyboardSimulator.read_cmd_seq(command_sequence)
                        keyboardSimulator.end()
                        command_start = False
                        logger.info(f"â–¶ï¸  {command_name}ï¼š{command_sequence}")
            else:
                if command_start and time.time() - ticker > CMD_TIMEOUT:
                    keyboardSimulator.end()
                    command_start = False
                    logger.info(f"âŒ  æŒ‡ä»¤è¢«å–æ¶ˆ")
